{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['read']\n",
      "['read', 'tags']\n",
      "['read', 'tags', 'smartCrops']\n",
      "['read']\n",
      "['read', 'tags']\n",
      "['read', 'tags', 'smartCrops']\n",
      "['read', 'smartCrops']\n",
      "['smartCrops']\n",
      "[]\n",
      "ko\n",
      "en\n",
      "ko\n",
      "en\n",
      "['tags']\n",
      "['tags', 'smartCrops']\n",
      "['tags', 'smartCrops', 'people']\n",
      "['tags']\n",
      "['tags', 'smartCrops']\n",
      "['tags', 'smartCrops', 'people']\n",
      "['tags', 'smartCrops', 'people', 'denseCaptions']\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "FEATURES = ['read', 'tags', 'smartCrops', 'people', 'caption', 'denseCaptions', 'objects' ]\n",
    "\n",
    "def request_vision(features, image_path):\n",
    "    endpoint = f\"{ENDPOINT}computervision/imageanalysis:analyze?api-version=2024-02-01&features={\",\".join(features)}\"\n",
    "    # method : POST\n",
    "\n",
    "    headers = {\n",
    "\n",
    "        \"Ocp-Apim-Subscription-Key\" : comVi_key,\n",
    "        \"Content-Type\" : \"application/octet-stream\"\n",
    "\n",
    "    }\n",
    "\n",
    "    # image_path로 이미지를 바이너리 형태로 읽어서 전송\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_data = image_file.read()\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, data=image_data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def draw_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "# FEATURES = \"caption\"\n",
    "# request_vision(FEATURES, \"../ComputerVision/lotus.jpg\")\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    def change_image(image_path, features):\n",
    "\n",
    "        if image_path:\n",
    "            response_json = request_vision(features, image_path)\n",
    "            image = draw_image(image_path)\n",
    "            return image, response_json\n",
    "        else:\n",
    "            return None, None\n",
    "        \n",
    "    def change_features(features):\n",
    "        print(features)\n",
    "        return features\n",
    "    \n",
    "    def change_language(language):\n",
    "        print(language)\n",
    "        return language\n",
    "\n",
    "\n",
    "    # def upload_image(image_path):\n",
    "    #      print(\"upload image\", image_path)\n",
    "\n",
    "\n",
    "    with gr.Column():\n",
    "        language_radio = gr.Radio(label=\"언어 선택\", choices=[\"en\", \"ko\"], value=\"en\")\n",
    "        features_checkbox = gr.CheckboxGroup(label=\"Features\", choices=FEATURES)\n",
    "        smart_crop_textbox = gr.Textbox(label=\"Smart Crops\")\n",
    "\n",
    "    with gr.Column():\n",
    "        input_image = gr.Image(label=\"입력 이미지\", type=\"filepath\", height = 400)\n",
    "\n",
    "\n",
    "    \n",
    "    with gr.Row():\n",
    "        output_image = gr.Image(label=\"출력 이미지\", type=\"pil\", interactive=False)\n",
    "        output_json = gr.JSON(label=\"결과 JSON\")\n",
    "\n",
    "        \n",
    "    input_image.change(change_image, inputs=[input_image, features_checkbox], outputs=[output_image, output_json])\n",
    "    language_radio.change(change_language, inputs=[language_radio], outputs=[language_radio])\n",
    "    features_checkbox.change(change_features, inputs=[features_checkbox], outputs=[features_checkbox])\n",
    "\n",
    "\n",
    "demo.launch()\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
