{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install azure-cognitiveservices-vision-customvision\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필수 기본 정보 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer, Predictor 객체화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region, ExportPlatform\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import os, time, uuid\n",
    "\n",
    "training_credentials = ApiKeyCredentials(in_headers={\"Training-key\" : training_key})\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\" : prediction_key})\n",
    "\n",
    "trainer = CustomVisionTrainingClient(endpoint=training_endpoint, credentials=training_credentials)\n",
    "predictor = CustomVisionPredictionClient(endpoint=prediction_endpoint, credentials=prediction_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT :  4c603e34-e3a3-4cb5-a6c7-6502f2e00c11 b022-kitchen-compact\n",
      "DOMAIN :  2e37d7fb-3a54-486a-b4d6-cfc369af0018 Classification General [A2]\n",
      "DOMAIN :  a8e3c40f-fb4a-466f-832a-5e457ae4a344 Classification General [A1]\n",
      "DOMAIN :  ee85a74c-405e-4adc-bb47-ffa8ca0c9f31 Classification General\n",
      "DOMAIN :  c151d5b5-dd07-472a-acc8-15d29dea8518 Classification Food\n",
      "DOMAIN :  ca455789-012d-4b50-9fec-5bb63841c793 Classification Landmarks\n",
      "DOMAIN :  b30a91ae-e3c1-4f73-a81e-c270bff27c39 Classification Retail\n",
      "DOMAIN :  45badf75-3591-4f26-a705-45678d3e9f5f Classification Adult\n",
      "DOMAIN :  a1db07ca-a19a-4830-bae8-e004a42dc863 Classification General (compact) [S1]\n",
      "DOMAIN :  0732100f-1a38-4e49-a514-c9b44c697ab5 Classification General (compact)\n",
      "DOMAIN :  8882951b-82cd-4c32-970b-d5f8cb8bf6d7 Classification Food (compact)\n",
      "DOMAIN :  b5cfd229-2ac7-4b2b-8d0a-2b0661344894 Classification Landmarks (compact)\n",
      "DOMAIN :  6b4faeda-8396-481b-9f8b-177b9fa3097f Classification Retail (compact)\n",
      "DOMAIN :  9c616dff-2e7d-ea11-af59-1866da359ce6 ObjectDetection General [A1]\n",
      "DOMAIN :  da2e3a8a-40a5-4171-82f4-58522f70fbc1 ObjectDetection General\n",
      "DOMAIN :  1d8ffafe-ec40-4fb2-8f90-72b3b6cecea4 ObjectDetection Logo\n",
      "DOMAIN :  3780a898-81c3-4516-81ae-3a139614e1f3 ObjectDetection Products on Shelves\n",
      "DOMAIN :  7ec2ac80-887b-48a6-8df9-8b1357765430 ObjectDetection General (compact) [S1]\n",
      "DOMAIN :  a27d5ca5-bb19-49d8-a70a-fec086c47f5b ObjectDetection General (compact)\n"
     ]
    }
   ],
   "source": [
    "# 프로젝트는 Custom Vision에서 하나의 학습 모델을 의미하며, 특정 데이터셋과 설정을 포함\n",
    "for project in trainer.get_projects():\n",
    "    print(\"PROJECT : \", project.id, project.name)\n",
    "\n",
    "\n",
    "\n",
    "# 도메인은 모델이 어떤 종류의 이미지 데이터를 학습하는지 정의하는 설정\n",
    "for domain in trainer.get_domains():\n",
    "    print(\"DOMAIN : \", domain.id,domain.type,  domain.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프로젝트: 4c603e34-e3a3-4cb5-a6c7-6502f2e00c11\n"
     ]
    }
   ],
   "source": [
    "project_name = \"b022-kitchen-compact\"\n",
    "project_description = \"포크와 가위를 감지하는 모델\"\n",
    "domain_id = None\n",
    "\n",
    "project_id = None\n",
    "\n",
    "# 기존 프로젝트 있는 지 확인\n",
    "for project in trainer.get_projects():\n",
    "    if project.name == project_name:\n",
    "\n",
    "        # 기존에 이미 프로젝트 존재하고 있으면 프로젝트 아이디를 가져온다\n",
    "        project_id = project.id\n",
    "        break\n",
    "\n",
    "# 도메인 정보를 체크, 원하는 도메인 정보와 일치할 경우, 도메인 아이디를 들고 온다\n",
    "for domain in trainer.get_domains():\n",
    "    if domain.type == \"ObjectDetection\" and domain.name == \"General (compact)\":\n",
    "        domain_id = domain.id\n",
    "        break\n",
    "\n",
    "# 도메인 아이디가 있음(도메인 타입과 도메인 네임이 원하는 것과 일치)\n",
    "# -> 프로젝트를 만들거나 프로젝트 들고 옴\n",
    "if domain_id:\n",
    "   \n",
    "\n",
    "    # 이미 프로젝트가 존재하는 경우, 프로젝트를 가져온다\n",
    "    if project_id:\n",
    "        print(\"프로젝트:\", project_id)\n",
    "        project = trainer.get_project(project_id=project_id)\n",
    "\n",
    "    # 프로젝트 없는 경우, 프로젝트 만들기\n",
    "    else:\n",
    "        project = trainer.create_project(project_name, project_description, domain_id)\n",
    "    \n",
    "#print(project_id, domain_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 태그 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<azure.cognitiveservices.vision.customvision.training.models._models_py3.Tag object at 0x10b1ff350>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.Tag object at 0x10b1ff790>]\n",
      "fork already exists\n",
      "scissors already exists\n",
      "2361ce68-b9df-411d-b541-2e713dcadff5 fork\n",
      "3cf385c6-3ec7-4307-a6af-3833d54fb622 scissors\n"
     ]
    }
   ],
   "source": [
    "exist_tag_list = trainer.get_tags(project_id=project.id)\n",
    "print(exist_tag_list)\n",
    "\n",
    "fork_tag = None\n",
    "scissors_tag = None\n",
    "\n",
    "# fork_tag = trainer.create_tag(project_id=project.id, name=\"fork\")\n",
    "# scissors_tag = trainer.create_tag(project_id=project.id, name=\"scissors\")\n",
    "\n",
    "# 태그가 있으면 여기로\n",
    "for tag in exist_tag_list:\n",
    "    if tag.name == \"fork\":\n",
    "        print(\"fork already exists\")\n",
    "        fork_tag = tag\n",
    "    elif tag.name == \"scissors\":\n",
    "        print(\"scissors already exists\")\n",
    "        scissors_tag = tag\n",
    "\n",
    "# 태그 없으면 태그 추가\n",
    "if fork_tag is None:\n",
    "    print(\"create fork Tag\")\n",
    "    fork_tag = trainer.create_tag(project_id=project.id, name=\"fork\")\n",
    "\n",
    "if scissors_tag is None:\n",
    "    print(\"create scissors Tag\")\n",
    "    scissors_tag = trainer.create_tag(project_id=project.id, name=\"scissors\")\n",
    "\n",
    "print(fork_tag.id, fork_tag.name)\n",
    "print(scissors_tag.id, scissors_tag.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 바운드 박스 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 별 객체 바운딩 박스 지정\n",
    "# [x, y, width, height]\n",
    "fork_image_regions = {\n",
    "    \"fork_1\": [ 0.145833328, 0.3509314, 0.5894608, 0.238562092 ],\n",
    "    \"fork_2\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"fork_3\": [ 0.09191177, 0.0682516545, 0.757352948, 0.6143791 ],\n",
    "    \"fork_4\": [ 0.254901975, 0.185898721, 0.5232843, 0.594771266 ],\n",
    "    \"fork_5\": [ 0.2365196, 0.128709182, 0.5845588, 0.71405226 ],\n",
    "    \"fork_6\": [ 0.115196079, 0.133611143, 0.676470637, 0.6993464 ],\n",
    "    \"fork_7\": [ 0.164215669, 0.31008172, 0.767156839, 0.410130739 ],\n",
    "    \"fork_8\": [ 0.118872553, 0.318251669, 0.817401946, 0.225490168 ],\n",
    "    \"fork_9\": [ 0.18259804, 0.2136765, 0.6335784, 0.643790841 ],\n",
    "    \"fork_10\": [ 0.05269608, 0.282303959, 0.8088235, 0.452614367 ],\n",
    "    \"fork_11\": [ 0.05759804, 0.0894935, 0.9007353, 0.3251634 ],\n",
    "    \"fork_12\": [ 0.3345588, 0.07315363, 0.375, 0.9150327 ],\n",
    "    \"fork_13\": [ 0.269607842, 0.194068655, 0.4093137, 0.6732026 ],\n",
    "    \"fork_14\": [ 0.143382356, 0.218578458, 0.7977941, 0.295751631 ],\n",
    "    \"fork_15\": [ 0.19240196, 0.0633497, 0.5710784, 0.8398692 ],\n",
    "    \"fork_16\": [ 0.140931368, 0.480016381, 0.6838235, 0.240196079 ],\n",
    "    \"fork_17\": [ 0.305147052, 0.2512582, 0.4791667, 0.5408496 ],\n",
    "    \"fork_18\": [ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "    \"fork_19\": [ 0.219362751, 0.141781077, 0.5919118, 0.6683006 ],\n",
    "    \"fork_20\": [ 0.180147052, 0.239820287, 0.6887255, 0.235294119 ]\n",
    "}\n",
    " \n",
    "scissors_image_regions = {\n",
    "    \"scissors_1\": [ 0.4007353, 0.194068655, 0.259803921, 0.6617647 ],\n",
    "    \"scissors_2\": [ 0.426470578, 0.185898721, 0.172794119, 0.5539216 ],\n",
    "    \"scissors_3\": [ 0.289215684, 0.259428144, 0.403186262, 0.421568632 ],\n",
    "    \"scissors_4\": [ 0.343137264, 0.105833367, 0.332107842, 0.8055556 ],\n",
    "    \"scissors_5\": [ 0.3125, 0.09766343, 0.435049027, 0.71405226 ],\n",
    "    \"scissors_6\": [ 0.379901975, 0.24308826, 0.32107842, 0.5718954 ],\n",
    "    \"scissors_7\": [ 0.341911763, 0.20714055, 0.3137255, 0.6356209 ],\n",
    "    \"scissors_8\": [ 0.231617644, 0.08459154, 0.504901946, 0.8480392 ],\n",
    "    \"scissors_9\": [ 0.170343131, 0.332957536, 0.767156839, 0.403594762 ],\n",
    "    \"scissors_10\": [ 0.204656869, 0.120539248, 0.5245098, 0.743464053 ],\n",
    "    \"scissors_11\": [ 0.05514706, 0.159754932, 0.799019635, 0.730392158 ],\n",
    "    \"scissors_12\": [ 0.265931368, 0.169558853, 0.5061275, 0.606209159 ],\n",
    "    \"scissors_13\": [ 0.241421565, 0.184264734, 0.448529422, 0.6830065 ],\n",
    "    \"scissors_14\": [ 0.05759804, 0.05027781, 0.75, 0.882352948 ],\n",
    "    \"scissors_15\": [ 0.191176474, 0.169558853, 0.6936275, 0.6748366 ],\n",
    "    \"scissors_16\": [ 0.1004902, 0.279036, 0.6911765, 0.477124184 ],\n",
    "    \"scissors_17\": [ 0.2720588, 0.131977156, 0.4987745, 0.6911765 ],\n",
    "    \"scissors_18\": [ 0.180147052, 0.112369314, 0.6262255, 0.6666667 ],\n",
    "    \"scissors_19\": [ 0.333333343, 0.0274019931, 0.443627447, 0.852941155 ],\n",
    "    \"scissors_20\": [ 0.158088237, 0.04047389, 0.6691176, 0.843137264 ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 업로드 : labeling 을 위한 구역 설정, 태그 포함해서 파일 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c307a10>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c3056a0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304590>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304360>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304a60>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304830>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c3048a0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c3046e0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304910>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304b40>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304bb0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304c20>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304d70>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10bff0360>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304de0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304ec0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304f30>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c304e50>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c305be0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageFileCreateEntry object at 0x10c305a20>]\n",
      "IMAGE LIST LENGTH :  40\n",
      "{'additional_properties': {}, 'is_batch_successful': True, 'images': [<azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31d710>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31e2e0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31dc50>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31df60>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31e0b0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31e3c0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31e510>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31e580>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31e6d0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31e660>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31e820>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31e900>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c31e9e0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c374c90>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c374d70>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c374e50>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c374f30>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375010>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c3750f0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c3751d0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c3752b0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375390>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375470>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375550>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375630>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375710>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c3757f0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c3758d0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c3759b0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375a90>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375b70>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375c50>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375d30>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375e10>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375ef0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c375fd0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c3760b0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c376190>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c376270>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x10c376350>]}\n",
      "Succeeded\n"
     ]
    }
   ],
   "source": [
    "image_list = list()\n",
    "\n",
    "# fork_image_region 정보 -> x, y, width, height 좌표를 들고와서 Region 정보를 만들어준다\n",
    "for file_name in fork_image_regions.keys():\n",
    "    with open(\"./fork/{}.jpg\".format(file_name), \"rb\") as image:\n",
    "        left, top, width, height = fork_image_regions[file_name]\n",
    "        region_list = [Region(tag_id = fork_tag.id, left=left, top=top, width=width, height=height)]\n",
    "\n",
    "        # print(image)\n",
    "        image_data = image.read()\n",
    "        # image_data를 ImageFileCreateEntry를 만들어서 파일 리스트에 넣어준다.\n",
    "        image_list.append(ImageFileCreateEntry(name=file_name, contents=image_data, regions=region_list))\n",
    "\n",
    "print(image_list)\n",
    "\n",
    "for file_name in scissors_image_regions.keys():\n",
    "    with open(\"./scissors/{}.jpg\".format(file_name), \"rb\") as image:\n",
    "        left, top, width, height = scissors_image_regions[file_name]\n",
    "        region_list = [Region(tag_id = scissors_tag.id, left=left, top=top, width=width, height=height)]\n",
    "\n",
    "\n",
    "        # print(image)\n",
    "        image_data = image.read()\n",
    "        image_list.append(ImageFileCreateEntry(name=file_name, contents=image_data, regions=region_list))\n",
    "\n",
    "# for c in image_list:\n",
    "#     print(c)\n",
    "\n",
    "# print(len(image_list))\n",
    "\n",
    "print(\"IMAGE LIST LENGTH : \", len(image_list))\n",
    "\n",
    "upload_result = trainer.create_images_from_files(project_id=project.id, batch=ImageFileCreateBatch(images=image_list))\n",
    "\n",
    "print(upload_result)\n",
    "\n",
    "if upload_result.is_batch_successful:\n",
    "    print(\"Succeeded\")\n",
    "else:\n",
    "    for image in upload_result.images:\n",
    "        print(\"{} : {} \".format(image.source_url, image.status))\n",
    "\n",
    "\n",
    "# print(image_data_fork)\n",
    "# print(image_data_scissors)\n",
    "\n",
    "# from IPython.display import display, Image\n",
    "# display(Image(data=image_data_fork))\n",
    "# display(Image(data=image_data_scissors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Training\n",
      "Training Status : Completed\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "exist_iteration_list = trainer.get_iterations(project_id=project.id)\n",
    "\n",
    "if len(exist_iteration_list) > 0:\n",
    "    iteration = exist_iteration_list[0]\n",
    "else:\n",
    "    iteration = trainer.train_project(project_id=project.id)\n",
    "\n",
    "print(iteration.status)\n",
    "\n",
    "while iteration.status == \"Training\":\n",
    "    iteration = trainer.get_iteration(project_id=project.id, iteration_id=iteration.id)\n",
    "    print(\"Training Status : {}\".format(iteration.status))\n",
    "    time.sleep(5)\n",
    "\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_name = \"b022-kitchen-OD\"\n",
    "trainer.publish_iteration(project_id=project.id, iteration_id=iteration.id, publish_name=publish_name, prediction_id=prediction_resource_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scissors : 97.72%\n",
      "{'additional_properties': {}, 'left': 0.14982024, 'top': 0.1849069, 'width': 0.6387608, 'height': 0.69022036}\n",
      "fork : 12.07%\n",
      "{'additional_properties': {}, 'left': 0.2339265, 'top': 0.27906013, 'width': 0.721138, 'height': 0.61512613}\n"
     ]
    }
   ],
   "source": [
    "with open(\"./test/test_image.jpg\", \"rb\") as image:\n",
    "    image_data = image.read()\n",
    "\n",
    "# display(Image(data=image_data))\n",
    "\n",
    "# 이미지 파일 사용\n",
    "# response = predictor.detect_image(project_id=project.id, published_name=publish_name, image_data=image_data)\n",
    "\n",
    "# url 이용\n",
    "response = predictor.detect_image_url(project_id=project.id, published_name=publish_name, url=\"https://cafe24.poxo.com/ec01/bibon1/jy78sT5iv9X+V5IHQBaKwrjoUZw7/nGXjx58SNFF4bK6NrHp9v6yW73e7/DyTNtncYBJmFI45IbmtzNo91A3rQ==/_/web/product/big/202101/833fa88eae073a583699cc737f0b8a91.jpg\")\n",
    "\n",
    "\n",
    "for prediction in response.predictions:\n",
    "    tag_name = prediction.tag_name\n",
    "    probability = prediction.probability\n",
    "    bounding_box = prediction.bounding_box\n",
    "\n",
    "# print(response)\n",
    "\n",
    "    if probability > 0.1:\n",
    "        print(\"{} : {:0.2f}%\".format(tag_name, probability*100))\n",
    "        print(bounding_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export(모델 다운로드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "CustomVisionErrorException",
     "evalue": "1886cc7f-2eb3-4379-a16b-6cbe8734dd0a is already queued for export",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCustomVisionErrorException\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m export = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplatform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExportPlatform\u001b[49m\u001b[43m.\u001b[49m\u001b[43monnx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(export)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MSAI6/GitHubConnect/Azure_OpenAI/openai/lib/python3.13/site-packages/azure/cognitiveservices/vision/customvision/training/operations/_custom_vision_training_client_operations.py:2241\u001b[39m, in \u001b[36mCustomVisionTrainingClientOperationsMixin.export_iteration\u001b[39m\u001b[34m(self, project_id, iteration_id, platform, flavor, custom_headers, raw, **operation_config)\u001b[39m\n\u001b[32m   2238\u001b[39m response = \u001b[38;5;28mself\u001b[39m._client.send(request, stream=\u001b[38;5;28;01mFalse\u001b[39;00m, **operation_config)\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m200\u001b[39m]:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m models.CustomVisionErrorException(\u001b[38;5;28mself\u001b[39m._deserialize, response)\n\u001b[32m   2243\u001b[39m deserialized = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n",
      "\u001b[31mCustomVisionErrorException\u001b[39m: 1886cc7f-2eb3-4379-a16b-6cbe8734dd0a is already queued for export"
     ]
    }
   ],
   "source": [
    "export = trainer.export_iteration(project_id=project.id, iteration_id=iteration.id, platform=ExportPlatform.onnx)\n",
    "print(export)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'platform': 'ONNX', 'status': 'Done', 'download_uri': 'https://irisprodeutraining.blob.core.windows.net:443/m-4c603e34e3a34cb5a6c76502f2e00c11/1886cc7f2eb34379a16b6cbe8734dd0a.ONNX.zip?skoid=ae506968-e136-4ce1-b90f-4723f7085af6&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skt=2025-03-26T08%3A04%3A51Z&ske=2025-03-27T08%3A04%3A51Z&sks=b&skv=2021-08-06&sv=2021-08-06&spr=https&st=2025-03-26T08%3A04%3A51Z&se=2025-03-27T08%3A04%3A51Z&sr=b&sp=r&sig=BYV5KxAyq%2FDfMo3bciI6JvqZjsOPZpqXw%2F1rfvbfR4Y%3D', 'flavor': None, 'newer_version_available': False}\n"
     ]
    }
   ],
   "source": [
    "exports = trainer.get_exports(project_id=project.id, iteration_id=iteration.id)\n",
    "export = exports[-1]\n",
    "print(export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(export.download_uri)\n",
    "with open(\"kitchen-v1.zip\", \"wb\") as file:\n",
    "    file.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.21.0-cp313-cp313-macosx_13_0_universal2.whl.metadata (4.5 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/parkjiyon/Desktop/MSAI6/GitHubConnect/Azure_OpenAI/openai/lib/python3.13/site-packages (from onnxruntime) (2.2.3)\n",
      "Requirement already satisfied: packaging in /Users/parkjiyon/Desktop/MSAI6/GitHubConnect/Azure_OpenAI/openai/lib/python3.13/site-packages (from onnxruntime) (24.2)\n",
      "Collecting protobuf (from onnxruntime)\n",
      "  Downloading protobuf-6.30.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting sympy (from onnxruntime)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading onnxruntime-1.21.0-cp313-cp313-macosx_13_0_universal2.whl (33.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading protobuf-6.30.1-cp39-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, flatbuffers, sympy, protobuf, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-25.2.10 humanfriendly-10.0 mpmath-1.3.0 onnxruntime-1.21.0 protobuf-6.30.1 sympy-1.13.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
